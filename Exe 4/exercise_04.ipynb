{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exercise 4: Word Embeddings",
   "id": "6e944d31a1f9c682"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter"
   ],
   "id": "5900bf44d5dc72b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sorter(item):\n",
    "    \"\"\" Function tha gets only the first number of the name of the file and organizes the files base on that\"\"\"\n",
    "    \n",
    "    return int(os.path.basename(item).split('_')[0])\n",
    "\n",
    "def read_raw_text(path_data):\n",
    "    \"\"\" \n",
    "    Function for reading the raw data in the .txt files. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_data: str\n",
    "        path of the folder that contains the data that is going to be used. (should be test or train)\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    data,scores: array_like\n",
    "        Data arrays, X is an array of shape [#documents of the dataset, #words in the vocabulary], y is an array of shape [#documents,] \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    scores = []\n",
    "    \n",
    "    sentiments = ['pos', 'neg']\n",
    "    for sentiment in sentiments:\n",
    "        path_vocab_pos = os.path.join(\".\", \"aclImdb\", path_data, sentiment, \"*.txt\")\n",
    "        \n",
    "        for filename in sorted(glob.glob(path_vocab_pos), key=sorter):\n",
    "            \n",
    "            with open(filename, encoding='utf8') as f:\n",
    "                \n",
    "                lines = f.read()\n",
    "                \n",
    "                data.append(lines)\n",
    "                scores.append(int(os.path.basename(filename).split('_')[1].strip('.txt')))\n",
    "    return data, scores"
   ],
   "id": "190ea7ab837c69c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import the data\n",
    "corpus, _ = read_raw_text('train')"
   ],
   "id": "55133a24be572934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def pre_process(\n",
    "    reviews,\n",
    "    tokenize_punct=False,\n",
    "    lowercase=False,\n",
    "    remove_punct=False,\n",
    "    remove_high_freq_terms=False,\n",
    "    high_freq_threshold=0.5,\n",
    "    replace_numbers=False\n",
    "):\n",
    "    # todo copy the code from the previous exercise\n",
    "\n",
    "tokenized_corpus = pre_process(corpus, tokenize_punct=True, lowercase=True, remove_punct=True)"
   ],
   "id": "78fc9d82d39de68c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reduce the corpus if you are facing performance issues\n",
    "tokenized_corpus = tokenized_corpus[:10]"
   ],
   "id": "755f7b4069b6260",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 1: CBOW",
   "id": "2bc156b148c732d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parameters (change these as wanted)\n",
    "CONTEXT_SIZE = 2  # Window size on each side\n",
    "EMBEDDING_DIM = 10\n",
    "PAD_TOKEN = '<PAD>'\n",
    "\n",
    "# Vocabulary\n",
    "vocab = list(set(word for sentence in tokenized_corpus for word in sentence))\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocab Size', vocab_size)\n",
    "print('Context Size', CONTEXT_SIZE)\n",
    "print('Embedding Dimension', EMBEDDING_DIM)"
   ],
   "id": "6afc8ca6d284bf9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "idx_to_word",
   "id": "1b0d180b5bc84ad6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add PAD_TOKEN to vocab\n",
    "\n",
    "# Pad sentences\n",
    "\n",
    "# Use padded sentences to create training data (i.e., context-target pairs, e.g, ('is', ['bromwell', 'high', 'a', 'cartoon']))\n"
   ],
   "id": "2caf88602aabaf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define CBOW model\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        # todo\n",
    "        \n",
    "    def forward(self, context_idxs):\n",
    "        # todo"
   ],
   "id": "4c1b87710020fc0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM)\n",
    "# todo"
   ],
   "id": "b1323b4691c8e4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_cbow(model, context_words):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        context_idxs = torch.tensor([word_to_idx[w] for w in context_words], dtype=torch.long)\n",
    "        output = model(context_idxs)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        top_prob, top_idx = torch.topk(probs, 5)  # top 5 predictions\n",
    "\n",
    "        print(f\"Context: {context_words}\")\n",
    "        print(\"Top predictions for center word:\")\n",
    "        for prob, idx in zip(top_prob[0], top_idx[0]):\n",
    "            print(f\"  {idx_to_word[idx.item()]}: {prob.item():.4f}\")\n",
    "\n",
    "# Example: I didn't know this -> [i], [didn], [t], [know], [this]\n",
    "context_example = ['i', 'didn', 'know', 'this']\n",
    "evaluate_cbow(model, context_example)"
   ],
   "id": "7c25d8ff938e2801",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 2: Skip-Gram",
   "id": "5e8d22c8e4bd8c72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare training data for SkipGram, i.e. (center_word, context_words), e.g., ('is', ['bromwell', 'high', 'a', 'cartoon'])\n",
    "# Hint: You might be able to reuse the data from CBOW"
   ],
   "id": "f336562a89e0b9a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super().__init__()\n",
    "        # todo\n",
    "\n",
    "    def forward(self, center_word_idx):\n",
    "        # todo"
   ],
   "id": "a3768bb5eaf7750c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SkipGram(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "# todo"
   ],
   "id": "2ae8c8bbe08e906b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_skipgram(model, center_word):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_idx = torch.tensor([word_to_idx[center_word]], dtype=torch.long)  # (1,)\n",
    "        output = model(input_idx)  # (1, context_size*2, vocab_size)\n",
    "        \n",
    "        # For each context position, get top predictions\n",
    "        context_preds = output.squeeze(0)  # (context_size*2, vocab_size)\n",
    "        \n",
    "        print(f\"Center word: '{center_word}'\")\n",
    "        print(\"Top predicted context words per context position:\")\n",
    "        \n",
    "        for pos, preds in enumerate(context_preds):\n",
    "            probs = torch.softmax(preds, dim=0)  # softmax over vocab dimension\n",
    "            top_prob, top_idx = torch.topk(probs, 5)\n",
    "            print(f\" Context position {pos+1}:\")\n",
    "            for prob, idx in zip(top_prob, top_idx):\n",
    "                print(f\"   {idx_to_word[idx.item()]}: {prob.item():.4f}\")\n",
    "            print()\n",
    "\n",
    "# Example usage\n",
    "center_word_example = 'can'\n",
    "evaluate_skipgram(model, center_word_example)"
   ],
   "id": "12a2de3d23bd45fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3: Cosine Similarity\n",
    "Make sure that you have installed the package gensim."
   ],
   "id": "bf64c60906e47f34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#conda install -c conda-forge gensim -y",
   "id": "edc5469eec5181af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot"
   ],
   "id": "2dae65ed8b9b4145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 3 (a): Cosine Similarity",
   "id": "fd04ce26e1618203"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cosine_similarity(x, y):\n",
    "    pass # todo"
   ],
   "id": "19f0c2f644d52cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 3 (b)",
   "id": "341dd143b9fb14c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 1",
   "id": "c8b85a015e73c0e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model1 = KeyedVectors.load_word2vec_format(datapath('word2vec_pre_kv_c'), binary=False) ",
   "id": "f3d61bef439acf40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_vector_m1 = model1.get_vector('king')\n",
    "queen_vector_m1 = model1.get_vector('queen')\n",
    "man_vector_m1 = model1.get_vector('man')\n",
    "woman_vector_m1 = model1.get_vector('woman')"
   ],
   "id": "27bbb0bb5095b684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model1.key_to_index",
   "id": "8fc59d8b29bfa794",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 2",
   "id": "fa51200b3115175a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model2 = KeyedVectors.load_word2vec_format(datapath('high_precision.kv.bin'), binary=True) ",
   "id": "1863230ee617a5b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_vector_m2 = model2.get_vector('king')\n",
    "queen_vector_m2 = model2.get_vector('queen')\n",
    "man_vector_m2 = model2.get_vector('man')\n",
    "woman_vector_m2 = model2.get_vector('woman')"
   ],
   "id": "e0fc6ebd53904af7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model2.key_to_index",
   "id": "983221de39ed40a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 3",
   "id": "5ba4315621799da1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model3 = KeyedVectors.load_word2vec_format(datapath('euclidean_vectors.bin'), binary=True) ",
   "id": "424f5f1f1e6255ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_vector_m3 = model3.get_vector('king')\n",
    "queen_vector_m3 = model3.get_vector('queen')\n",
    "man_vector_m3 = model3.get_vector('man')\n",
    "woman_vector_m3 = model3.get_vector('woman')"
   ],
   "id": "c3d8b1800eb7dc5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model3.key_to_index",
   "id": "634e71062b11389f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Analogy Example 1",
   "id": "4680d6a91045774d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_mins_man_plus_woman_m3 = (king_vector_m3 - man_vector_m3) + woman_vector_m3\n",
    "\n",
    "# Make sure you have implemented cosine similarity. \n",
    "cosine_similarity(king_mins_man_plus_woman_m3, queen_vector_m3)"
   ],
   "id": "bfe22173b6167b92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model 4",
   "id": "318b2f0b3af40ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "word2vec_google = gensim.downloader.load('word2vec-google-news-300');",
   "id": "81ae4a24504312ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(word2vec_google.get_vector('king'))",
   "id": "561e32e7da1a6187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# you can also try the GLOVE model\n",
    "glove_google = gensim.downloader.load('glove-wiki-gigaword-100');"
   ],
   "id": "6805490c424e7880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(glove_google.get_vector('king'))",
   "id": "4adb443a866e9fb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model4 = word2vec_google",
   "id": "b7464acc6b77a306",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_vector_m4 = model4.get_vector('king')\n",
    "queen_vector_m4 = model4.get_vector('queen')\n",
    "man_vector_m4 = model4.get_vector('man')\n",
    "woman_vector_m4 = model4.get_vector('woman')"
   ],
   "id": "aba910248b1d4f72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Analogy Example 2",
   "id": "652677473d83b816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "king_mins_man_plus_woman_m4 = (king_vector_m4 - man_vector_m4) + woman_vector_m4\n",
    "\n",
    "# Make sure you have implemented cosine similarity. \n",
    "cosine_similarity(king_mins_man_plus_woman_m4, queen_vector_m4)"
   ],
   "id": "396d43cd93f0c092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Find a method to search for similar words given a word\n",
    "# Hint: you can use a method of the word2vec_google object\n",
    "\n",
    "similar_words = model4.IDENTIFIED_METHOD('phone', topn=10)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ],
   "id": "459734e0cacc738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "similar_words = model4.IDENTIFIED_METHOD('king', topn=10)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ],
   "id": "ed0835f5923afa0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# try to find at least five analogies using the method you found above\n",
   "id": "ef941245b07d523e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Theoretical Question #8",
   "id": "f1a03c120788ab27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "word2vec_google.IDENTIFIED_METHOD(king_mins_man_plus_woman_m4) # First answer will be King",
   "id": "fc6e1ef4589d3f06",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
