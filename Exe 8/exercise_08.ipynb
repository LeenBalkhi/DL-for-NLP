{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "uOYcTVi6vsLJ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from random import randrange, shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-pre-training\n",
    "    training on known task t known.. \n",
    "    Task is not necassarly domain speciifc an pre-training is done on a big coprus, with task_t (characterstic. Large, captures the general properties of the language. focus isn't on the target task)\n",
    "    as an example; when using word2vec, or other pre-trained models, that have already been trainewd on the general lanuage, and adapting them or soecific taks, (followed by domain adaptation)\n",
    "    common tasks for pre-training are MLM and NSP to understand the language\n",
    "\n",
    "-domain adaptation \n",
    "    target task doesn't equal task used when training, which would require training on data linked to the target task. (i.e., adaptin to the specitic domain)\n",
    "    adaptation based on task s, unknown and doesnt' equal t\n",
    "    final model would be a pre-trained general-domain model, that would later on required fine tuning\n",
    "    same pre-training tasks\n",
    "\n",
    "-fine-tuning \n",
    "    (in simple words tweaking the hyperparameters of the model to get the best results) fin-tuning approach has a high impact on the results/\n",
    "    understanding the language\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jxU5OQIhY_0W"
   },
   "source": [
    "# Exercise 8: Encoder Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nr7ZIX0JZGLE"
   },
   "source": [
    "### Toy example based\n",
    "This code is based on code developed by Dong-Hyun Lee.\n",
    "\n",
    "\n",
    "Please, read carefully the code, since it could help you in the subsequent programming tasks. While you read the text, try to answer each of the questions that are presented in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "8iN-070y7KU3"
   },
   "outputs": [],
   "source": [
    "# Example of a single review. This review is a modified version of the first positive review of the dataset that we are using\n",
    "# Note that is a single review\n",
    "review = [\"Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \\\"Teachers\\\".\"\n",
    "        \"My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \\\"Teachers\\\".\"\n",
    "         \"The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students.\"\n",
    "         \"When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled  at  High.\"\n",
    "         \"A classic line: INSPECTOR: I'm here to sack one of your teachers, STUDENT: Welcome to Bromwell High.\"\n",
    "         \"I expect that many adults of my age think that Bromwell High is far fetched.\"\n",
    "         \"What a pity that it isn't!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT4GlPYU0kgf"
   },
   "outputs": [],
   "source": [
    "# Importantly, we are adding some special tokens to the vocabulary.\n",
    "# From now, start thinking what is tok1, tok2, tok3, and tok4 (based on there usage in create_B)\n",
    "TOK_1 = '[tok1]' # Padding? [PAD]\n",
    "TOK_2 = '[tok2]' #start of sentence ?? # [CLS]\n",
    "TOK_3 = '[tok3]' # seperator? [SEP]\n",
    "TOK_4 = '[tok4]' # [MASK]\n",
    "\n",
    "# Basic tokenizer - you should use your tokenizer from previous exercises or an improved version of the following code, but you can use the following code as a starting point\n",
    "def build_vocab_tokenize(reviews):\n",
    "    sentences = []\n",
    "    for rev in reviews:\n",
    "        parts = re.split(r'[.!?]+', rev)\n",
    "        for part in parts:\n",
    "            sent = part.strip().lower()\n",
    "            if not sent:\n",
    "                continue\n",
    "            sent = re.sub(r\"[^a-z0-9'\\s]\", \"\", sent)\n",
    "            sentences.append(sent)\n",
    "\n",
    "    all_words = \" \".join(sentences).split()\n",
    "    vocab = sorted(set(all_words))\n",
    "\n",
    "    tokens_2_index_dict = {TOK_1: 0, TOK_2: 1, TOK_3: 2, TOK_4: 3}\n",
    "\n",
    "    # The following loops should be familiar to you, since we have been doing this from exercise #2\n",
    "    init_index = len(tokens_2_index_dict)\n",
    "\n",
    "    # Create two dictionaries one for mapping index (ids) to tokens and one for tokens to index\n",
    "    for i, token in enumerate(vocab):\n",
    "        tokens_2_index_dict[token] = i + init_index\n",
    "\n",
    "    index_2_token = {}\n",
    "    for i, token in enumerate(tokens_2_index_dict):\n",
    "        index_2_token[i] = token\n",
    "\n",
    "    sentences_2_token_lst = [\n",
    "        [tokens_2_index_dict[word] for word in sent.split()]\n",
    "        for sent in sentences\n",
    "    ]\n",
    "    vocab_size = len(tokens_2_index_dict)\n",
    " \n",
    "    \"\"\"for sent in sentences:\n",
    "        print(sent)\"\"\"\n",
    "    return tokens_2_index_dict,index_2_token, vocab_size, sentences_2_token_lst, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[tok1]': 0,\n",
       "  '[tok2]': 1,\n",
       "  '[tok3]': 2,\n",
       "  '[tok4]': 3,\n",
       "  '35': 4,\n",
       "  'a': 5,\n",
       "  'about': 6,\n",
       "  'adults': 7,\n",
       "  'age': 8,\n",
       "  'all': 9,\n",
       "  'and': 10,\n",
       "  'as': 11,\n",
       "  'at': 12,\n",
       "  'believe': 13,\n",
       "  'bromwell': 14,\n",
       "  'burn': 15,\n",
       "  'can': 16,\n",
       "  'cartoon': 17,\n",
       "  'classic': 18,\n",
       "  'closer': 19,\n",
       "  'comedy': 20,\n",
       "  'down': 21,\n",
       "  'episode': 22,\n",
       "  'expect': 23,\n",
       "  'far': 24,\n",
       "  'fetched': 25,\n",
       "  'financially': 26,\n",
       "  'here': 27,\n",
       "  'high': 28,\n",
       "  \"high's\": 29,\n",
       "  'i': 30,\n",
       "  \"i'm\": 31,\n",
       "  'immediately': 32,\n",
       "  'in': 33,\n",
       "  'insightful': 34,\n",
       "  'inspector': 35,\n",
       "  'is': 36,\n",
       "  \"isn't\": 37,\n",
       "  'it': 38,\n",
       "  'knew': 39,\n",
       "  'lead': 40,\n",
       "  'life': 41,\n",
       "  'line': 42,\n",
       "  'many': 43,\n",
       "  'me': 44,\n",
       "  'much': 45,\n",
       "  'my': 46,\n",
       "  'of': 47,\n",
       "  'one': 48,\n",
       "  'other': 49,\n",
       "  'pathetic': 50,\n",
       "  'pettiness': 51,\n",
       "  'pity': 52,\n",
       "  'pomp': 53,\n",
       "  'profession': 54,\n",
       "  'programs': 55,\n",
       "  'ran': 56,\n",
       "  'reality': 57,\n",
       "  'recalled': 58,\n",
       "  'remind': 59,\n",
       "  'repeatedly': 60,\n",
       "  'right': 61,\n",
       "  'sack': 62,\n",
       "  'same': 63,\n",
       "  'satire': 64,\n",
       "  'saw': 65,\n",
       "  'school': 66,\n",
       "  'schools': 67,\n",
       "  'scramble': 68,\n",
       "  'see': 69,\n",
       "  'situation': 70,\n",
       "  'some': 71,\n",
       "  'student': 72,\n",
       "  'students': 73,\n",
       "  'such': 74,\n",
       "  'survive': 75,\n",
       "  'teachers': 76,\n",
       "  \"teachers'\": 77,\n",
       "  'teaching': 78,\n",
       "  'than': 79,\n",
       "  'that': 80,\n",
       "  'the': 81,\n",
       "  'their': 82,\n",
       "  'think': 83,\n",
       "  'through': 84,\n",
       "  'time': 85,\n",
       "  'to': 86,\n",
       "  'tried': 87,\n",
       "  'welcome': 88,\n",
       "  'what': 89,\n",
       "  'when': 90,\n",
       "  'which': 91,\n",
       "  'who': 92,\n",
       "  'whole': 93,\n",
       "  'years': 94,\n",
       "  'your': 95},\n",
       " {0: '[tok1]',\n",
       "  1: '[tok2]',\n",
       "  2: '[tok3]',\n",
       "  3: '[tok4]',\n",
       "  4: '35',\n",
       "  5: 'a',\n",
       "  6: 'about',\n",
       "  7: 'adults',\n",
       "  8: 'age',\n",
       "  9: 'all',\n",
       "  10: 'and',\n",
       "  11: 'as',\n",
       "  12: 'at',\n",
       "  13: 'believe',\n",
       "  14: 'bromwell',\n",
       "  15: 'burn',\n",
       "  16: 'can',\n",
       "  17: 'cartoon',\n",
       "  18: 'classic',\n",
       "  19: 'closer',\n",
       "  20: 'comedy',\n",
       "  21: 'down',\n",
       "  22: 'episode',\n",
       "  23: 'expect',\n",
       "  24: 'far',\n",
       "  25: 'fetched',\n",
       "  26: 'financially',\n",
       "  27: 'here',\n",
       "  28: 'high',\n",
       "  29: \"high's\",\n",
       "  30: 'i',\n",
       "  31: \"i'm\",\n",
       "  32: 'immediately',\n",
       "  33: 'in',\n",
       "  34: 'insightful',\n",
       "  35: 'inspector',\n",
       "  36: 'is',\n",
       "  37: \"isn't\",\n",
       "  38: 'it',\n",
       "  39: 'knew',\n",
       "  40: 'lead',\n",
       "  41: 'life',\n",
       "  42: 'line',\n",
       "  43: 'many',\n",
       "  44: 'me',\n",
       "  45: 'much',\n",
       "  46: 'my',\n",
       "  47: 'of',\n",
       "  48: 'one',\n",
       "  49: 'other',\n",
       "  50: 'pathetic',\n",
       "  51: 'pettiness',\n",
       "  52: 'pity',\n",
       "  53: 'pomp',\n",
       "  54: 'profession',\n",
       "  55: 'programs',\n",
       "  56: 'ran',\n",
       "  57: 'reality',\n",
       "  58: 'recalled',\n",
       "  59: 'remind',\n",
       "  60: 'repeatedly',\n",
       "  61: 'right',\n",
       "  62: 'sack',\n",
       "  63: 'same',\n",
       "  64: 'satire',\n",
       "  65: 'saw',\n",
       "  66: 'school',\n",
       "  67: 'schools',\n",
       "  68: 'scramble',\n",
       "  69: 'see',\n",
       "  70: 'situation',\n",
       "  71: 'some',\n",
       "  72: 'student',\n",
       "  73: 'students',\n",
       "  74: 'such',\n",
       "  75: 'survive',\n",
       "  76: 'teachers',\n",
       "  77: \"teachers'\",\n",
       "  78: 'teaching',\n",
       "  79: 'than',\n",
       "  80: 'that',\n",
       "  81: 'the',\n",
       "  82: 'their',\n",
       "  83: 'think',\n",
       "  84: 'through',\n",
       "  85: 'time',\n",
       "  86: 'to',\n",
       "  87: 'tried',\n",
       "  88: 'welcome',\n",
       "  89: 'what',\n",
       "  90: 'when',\n",
       "  91: 'which',\n",
       "  92: 'who',\n",
       "  93: 'whole',\n",
       "  94: 'years',\n",
       "  95: 'your'},\n",
       " 96,\n",
       " [[14, 28, 36, 5, 17, 20],\n",
       "  [38, 56, 12, 81, 63, 85, 11, 71, 49, 55, 6, 66, 41, 74, 11, 76],\n",
       "  [46,\n",
       "   4,\n",
       "   94,\n",
       "   33,\n",
       "   81,\n",
       "   78,\n",
       "   54,\n",
       "   40,\n",
       "   44,\n",
       "   86,\n",
       "   13,\n",
       "   80,\n",
       "   14,\n",
       "   29,\n",
       "   64,\n",
       "   36,\n",
       "   45,\n",
       "   19,\n",
       "   86,\n",
       "   57,\n",
       "   79,\n",
       "   36,\n",
       "   76],\n",
       "  [81,\n",
       "   68,\n",
       "   86,\n",
       "   75,\n",
       "   26,\n",
       "   81,\n",
       "   34,\n",
       "   73,\n",
       "   92,\n",
       "   16,\n",
       "   69,\n",
       "   61,\n",
       "   84,\n",
       "   82,\n",
       "   50,\n",
       "   77,\n",
       "   53,\n",
       "   81,\n",
       "   51,\n",
       "   47,\n",
       "   81,\n",
       "   93,\n",
       "   70,\n",
       "   9,\n",
       "   59,\n",
       "   44,\n",
       "   47,\n",
       "   81,\n",
       "   67,\n",
       "   30,\n",
       "   39,\n",
       "   10,\n",
       "   82,\n",
       "   73],\n",
       "  [90,\n",
       "   30,\n",
       "   65,\n",
       "   81,\n",
       "   22,\n",
       "   33,\n",
       "   91,\n",
       "   5,\n",
       "   72,\n",
       "   60,\n",
       "   87,\n",
       "   86,\n",
       "   15,\n",
       "   21,\n",
       "   81,\n",
       "   66,\n",
       "   30,\n",
       "   32,\n",
       "   58,\n",
       "   12,\n",
       "   28],\n",
       "  [5, 18, 42, 35, 31, 27, 86, 62, 48, 47, 95, 76, 72, 88, 86, 14, 28],\n",
       "  [30, 23, 80, 43, 7, 47, 46, 8, 83, 80, 14, 28, 36, 24, 25],\n",
       "  [89, 5, 52, 80, 38, 37]],\n",
       " ['bromwell high is a cartoon comedy',\n",
       "  'it ran at the same time as some other programs about school life such as teachers',\n",
       "  \"my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers\",\n",
       "  \"the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students\",\n",
       "  'when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high',\n",
       "  \"a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high\",\n",
       "  'i expect that many adults of my age think that bromwell high is far fetched',\n",
       "  \"what a pity that it isn't\"])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_vocab_tokenize(review)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RjYB8A2-sEDA"
   },
   "source": [
    "## Theoretical part 1 - code related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_X = 100 # what is X? maximum length per sequence \n",
    "size_B = 6 # What is B? batch size??\n",
    "max_pred_M = 10  # what is M? number of masked tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "XWlnMGJc0rRa"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_B(maxlen_X=maxlen_X, size_B=size_B, max_pred_M=max_pred_M\n",
    "             ,sentences=[] , sentences_2_tokens_lst=[], tokens_2_index_dict=[]):\n",
    "    assert size_B % 2 == 0, \"size_B should be even\"\n",
    "    \n",
    "    lst_B = []\n",
    "    positive_pair_X = 0\n",
    "    negative_pair_X = 0\n",
    "    number_sentences = len(sentences)\n",
    "\n",
    "    while positive_pair_X != size_B/2 or negative_pair_X != size_B/2: # we want 50% of something positive and 50% of something negative\n",
    "        tokens_X1_index = randrange(number_sentences)\n",
    "        tokens_X2_index = randrange(number_sentences)\n",
    "\n",
    "        tokens_X1 = sentences_2_tokens_lst[tokens_X1_index]\n",
    "        tokens_X2 = sentences_2_tokens_lst[tokens_X2_index]\n",
    "\n",
    "        #What are we doing here? WHy do we need to do this?\n",
    "        # for NSP tasks. differentianting between sentences. would we need to do that if we're not using NSP?\n",
    "        input_ids_X = [tokens_2_index_dict[TOK_2]] + tokens_X1 + [tokens_2_index_dict[TOK_3]] + tokens_X2 + [tokens_2_index_dict[TOK_3]]\n",
    "\n",
    "        int_max_number_pred = max(1,int(round(len(input_ids_X) * 0.15)))\n",
    "        n_pred_M =  min(max_pred_M, int_max_number_pred) # max - 15% of tokens in one STU\n",
    "        \n",
    "        # every token can be M? no, preset tokens [CLS] [SEP] are excluded. masking these would\n",
    "        cand_M_pos = []\n",
    "        for i, token in enumerate(input_ids_X):\n",
    "            if token != tokens_2_index_dict[TOK_2] and token != tokens_2_index_dict[TOK_3]:\n",
    "                cand_M_pos.append(i)\n",
    "\n",
    "        \n",
    "        shuffle(cand_M_pos) # Why do we need to shuffle this? to mask random tokens (that are not preset)\n",
    "        M_tokens = []\n",
    "        M_pos = []\n",
    "\n",
    "        #What is this loop iterating? after the shuffle, we're storing the randomly selected tokens for masking, (to use to check prediction), and then masking them with [tok4] [MASK]\n",
    "        for pos in cand_M_pos[:n_pred_M]:\n",
    "            M_pos.append(pos)\n",
    "            M_tokens.append(input_ids_X[pos])\n",
    "            input_ids_X[pos] = tokens_2_index_dict[TOK_4]\n",
    "\n",
    "\n",
    "        # Why do we need to pad input_ids_X? \n",
    "        #maked sure every input sequence has the same length (Batch, maxlen). padding here is looking at input\n",
    "        #to ensure all sequenecs are of the same length of training (uniform shape)\n",
    "        n_pad = maxlen_X - len(input_ids_X)\n",
    "        input_ids_X.extend([tokens_2_index_dict[TOK_1]] * n_pad)\n",
    "\n",
    "\n",
    "        \n",
    "        # What would happen if we do not have the conditional?\n",
    "        ## n_pred_M is the number of tokens to be masked in the given sequence, and max_pred_M is the maximum number of tokens to max.\n",
    "        # if our sequence length is too short then the number n_pred_max (we would have less tokens)\n",
    "        if max_pred_M > n_pred_M:\n",
    "            n_pad = max_pred_M - n_pred_M\n",
    "            M_tokens.extend([tokens_2_index_dict[TOK_1]] * n_pad)\n",
    "            M_pos.extend([tokens_2_index_dict[TOK_1]] * n_pad)\n",
    "\n",
    "        # What are we verifying with this conditional?\n",
    "        #for NSP, checks that the sentence are consecutive and that half are positive and half are negative\n",
    "        if tokens_X1_index + 1 == tokens_X2_index and positive_pair_X < size_B/2:\n",
    "            lst_B.append([input_ids_X, M_tokens, M_pos, True])\n",
    "            positive_pair_X += 1\n",
    "\n",
    "        elif tokens_X1_index + 1 != tokens_X2_index and negative_pair_X < size_B/2:\n",
    "            lst_B.append([input_ids_X, M_tokens, M_pos, False])\n",
    "            negative_pair_X += 1\n",
    "\n",
    "    return lst_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "BAUcEjBD01zF"
   },
   "outputs": [],
   "source": [
    "tokens_2_index_dict,_, _, sentences_2_token_lst, sentences = build_vocab_tokenize(review)\n",
    "B = create_B(sentences=sentences, sentences_2_tokens_lst= sentences_2_token_lst , tokens_2_index_dict=tokens_2_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_Xs, M_tokens, M_pos, isNext = map(torch.LongTensor, zip(*B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Tasks: Implementing an Encoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reuse the `SelfAttention` class from Exercise 6, but you might need to extend it to support masking (C.1.1.v).\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_k):\n",
    "        super().__init__()\n",
    "        # define the weight matrices W_Q, W_K, and W_V\n",
    "        self.model = d_model\n",
    "        self.d_k = d_k\n",
    "\n",
    "        # learnable weight matrices\n",
    "        self.W_Q = nn.Linear(d_model, d_k) #x @ weight + bias\n",
    "        self.W_K = nn.Linear(d_model, d_k) #x @ weight + bias\n",
    "        self.W_V = nn.Linear(d_model, d_k) #....\n",
    "\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        #vector production\n",
    "        W_Q = self.W_Q(x)\n",
    "        W_K = self.W_K(x)\n",
    "        W_V = self.W_V(x)\n",
    "         \n",
    "        #attention score using dot product between queries and keys\n",
    "        scores = torch.matmul (W_Q, W_K.transpose(-2,-1)) / np.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None: \n",
    "            #adding minus infinity to masked values (with 0 zero) to nullify after softmax\n",
    "            #-1e9\n",
    "            mask = mask.unsqueeze(1)\n",
    "            scores= scores.masked_fill(mask ==0, float('-inf'))\n",
    "        W_attention = F.softmax(scores, dim=-1)\n",
    "        #attention-weighted sum of the value vector\n",
    "        out = torch.matmul(W_attention, W_V)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.1.1 Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "\n",
    "        #concatination (head_1, head_2,... head_n)\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [SelfAttention(d_model, d_k) for _ in range (n_heads) ]\n",
    "        )\n",
    "        #linear projection/ dense layer\n",
    "        self.proj = nn.Linear(n_heads * d_k, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        head_output = []\n",
    "\n",
    "        #calling forward for each self-attention \n",
    "        for head in self.heads: \n",
    "            out = head(x, mask= mask)\n",
    "            head_output.append(out)\n",
    "        concat = torch.cat(head_output, dim =-1)\n",
    "\n",
    "        return self.proj(concat)\n",
    "    \n",
    "    # C.1.2 Add Residual Connection and LayerNorm\n",
    "class MultiHeadBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, d_k )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.attn(x, mask)\n",
    "        # input = x + atten_out residual connection\n",
    "        return self.norm(x + attn_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return self.norm(residual + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, dim_feedforward):\n",
    "        super().__init__()\n",
    "        self.mha_block = MultiHeadBlock(d_model, n_heads, d_k)\n",
    "        self.ff_block = FeedForward(d_model, dim_feedforward)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.mha_block(x, mask)\n",
    "        x = self.ff_block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, nhead=4, num_layers=8, dim_ff=128, max_len=100):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Embedding(max_len, embed_dim)\n",
    "        d_k = embed_dim // nhead\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(embed_dim, nhead, d_k, dim_ff)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, input_ids, mask=None):\n",
    "        b, seq = input_ids.size()\n",
    "        pos = torch.arange(seq, device=input_ids.device).unsqueeze(0).expand(b, -1)\n",
    "        x = self.tok_emb(input_ids) + self.pos_emb(pos)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "def load_imdb(n_samples=100):\n",
    "    dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "    # How many samples per class\n",
    "    n_per_class = n_samples // 2\n",
    "\n",
    "    # Filter each class\n",
    "    pos = dataset.filter(lambda x: x[\"label\"] == 1).shuffle(seed=42).select(range(n_per_class))\n",
    "    neg = dataset.filter(lambda x: x[\"label\"] == 0).shuffle(seed=42).select(range(n_per_class))\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    balanced = concatenate_datasets([pos, neg]).shuffle(seed=42)\n",
    "\n",
    "    texts = balanced[\"text\"]\n",
    "    labels = balanced[\"label\"]\n",
    "    return texts, labels\n",
    "\n",
    "texts, labels = load_imdb(n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel init with params\\nCrossEntropyloss. \\nlogits no activation\\ntrain \\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\"\"\"\n",
    "vocab_size\n",
    "embed_dim\n",
    "nhead\n",
    "num_layers ## encoder layers inside the encoder?\n",
    "dim_feedforward\n",
    "max_le ## max len of sequence?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "vocab_size = 10000      \n",
    "embed_dim = 64\n",
    "nhead = 4\n",
    "num_layers = 6\n",
    "dim_feedforward = 256\n",
    "max_len = 128\n",
    "num_epochs = 10\n",
    "# Training\n",
    "\n",
    "\"\"\" \n",
    "Model init with params\n",
    "CrossEntropyloss. \n",
    "logits no activation\n",
    "train \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of using multiple encoder blocks; you can train a huge model and drop encodel models to make the model more efficient. it gives the freedom to choose the number of blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is prepairing the data for an LLM spec MLM and NSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-training: general and large dataset (i.e., wikipedia or common crawl)\n",
    "\n",
    "domain: specialized domain (i.e., pubmed, twitter)\n",
    "\n",
    "fine-tuning: task specific datasets i.e., ones provided in the benchmark. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image: \n",
    "pretraining: imagenet   (learn edges, tectures, colos, shapes)\n",
    "domain adpation: RICO (apps design) adapt the learned concepty to the domain\n",
    "fine-tuning: UI classification (classifying the UIs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Pyenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
